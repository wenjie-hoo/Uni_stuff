{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c80a5289-a8e2-498a-a8ec-eb58d59081b3",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "## Markov model\n",
    "\n",
    "Surprisingly many processes happening in our lives we can model using a stochastic process depending only on the immediately preceding state of the process.\n",
    "One very classical example is ''random walk''(''birth and death chain'').\n",
    "The state space is $\\{0, 1, 2, \\ldots, L\\}$ The chain goes to the right with probability $p$ and to the left with probability $1-p$, additionally we assume that going left from 0 or going right from $L$ means staying put.\n",
    "\n",
    "Turning now to the formal definition, we say that $X_{n}$ is a discrete time\n",
    "Markov chain with transition matrix $p(i, j)$ if for any $j, i, i_{n-1}, \\ldots i_{0}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{equation:markov}\n",
    "P\\left(X_{n+1}=j | X_{n}=i, X_{n-1}=i_{n-1}, \\ldots, X_{0}=i_{0}\\right)=p(i, j).\n",
    "\\end{equation}\n",
    "\n",
    "Above equation explains well what we mean by phrase ''given the current\n",
    "state $X_n$, any other information about the past is irrelevant for predicting $X_{n+1}$''.\n",
    " We have restricted our attention to the temporally\n",
    "homogeneous case in which the transition probability\n",
    "\\begin{equation*}\n",
    "p(i, j)=P\\left(X_{n+1}=j | X_{n}=i\\right)\n",
    "\\end{equation*}\n",
    "does not depend on the time $n$.\n",
    "\n",
    "To better illustrate how the Markov process functions, let's look at the simple example.\n",
    "### Example 1\n",
    "\n",
    "Let r, s, w be three states, namely rainy, sunny and windy. The weather can transition from one state at time $n$ to another at time $n+1$ with probability $p(x_n, x_{n+1})$.\n",
    "\n",
    "We can assume that the model is constructed during the spring and it is sunny most of the time.\n",
    "We can define a state transition matrix:\n",
    "\n",
    "$$\\mathbf{A} = \n",
    "        \\begin{pmatrix}\n",
    "         & rainy   & sunny   & windy \\\\\n",
    "        rainy & 0.1 & 0.1 & 0.8 \\\\\n",
    "        sunny & 0.2 & 0.7 & 0.1 \\\\\n",
    "        windy & 0.2   & 0.7   & 0.1   \\\\\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## Observations\n",
    "\n",
    "We define HMM as follows:\n",
    "$$\n",
    "\\lambda=(\\mathbf{A}, \\mathbf{B}, \\mathbf{\\pi})\n",
    "$$\n",
    "where S is our state alphabet set, and V is the observation alphabet set:\n",
    "$$\n",
    "\\begin{aligned} S &=\\left(s_{1}, s_{2}, \\cdots, s_{N}\\right) \\\\ V &=\\left(v_{1}, v_{2}, \\cdots, v_{M}\\right). \\end{aligned}\n",
    "$$\n",
    "We define Q to be a fixed state sequence of length T, and corresponding observations O:\n",
    "$$\n",
    "\\begin{aligned} Q &=q_{1}, q_{2}, \\cdots, q_{T} \\\\ O &=o_{1}, o_{2}, \\cdots, o_{T} \\end{aligned}\n",
    "$$\n",
    "$\\mathbf{A}$ is a transition matrix, storing the probability of state j following state i. Note here that the state\n",
    "transition probabilities are independent of time:\n",
    "$$\n",
    "\\mathbf{A}=\\left[a_{i j}\\right], a_{i j}=P\\left(q_{t}=s_{j} | q_{t-1}=s_{i}\\right),\n",
    "$$\n",
    "$\\mathbf{B}$ is the observation matrix, storing the probability of observation k being produced from\n",
    "the state j, independent of t:\n",
    "$$\n",
    "\\mathbf{B}=\\left[b_{i}(k)\\right], b_{i}(k)=P\\left(x_{t}=v_{k} | q_{t}=s_{i}\\right),\n",
    "$$\n",
    "$\\pi$ is the initial probability matrix:\n",
    "$$\n",
    "\\mathbf{\\pi}=\\left[\\pi_{i}\\right], \\pi_{i}=P\\left(q_{1}=s_{i}\\right).\n",
    "$$\n",
    "Here, two assumptions are made by the model. The first is called the Markov assumption. It states\n",
    "that the current state is dependent only on the previous state. This represents the memory of\n",
    "the model:\n",
    "$$\n",
    "P\\left(q_{t} | q_{1}\\,\\ldots, q_{t-1}\\right)=P\\left(q_{t} | q_{t-1}\\right).\n",
    "$$\n",
    "The second one, called the independence assumption. states that the output observation at time t is dependent\n",
    "only on the current state and it is independent of previous observations and states:\n",
    "$$\n",
    "P\\left(o_{t} | o_{1}, \\ldots, o_{t-1}, q_{1}, \\ldots q_{t}\\right)=P\\left(o_{t} | q_{t}\\right).\n",
    "$$\n",
    "\n",
    "### Example\n",
    "<img src=\"Figures/HMM1.png\">\n",
    "\n",
    "**Figure 1:** Simple weather model with three different states: (R)ainy, (S)unny and (W)indy.\n",
    "\n",
    "<img src=\"Figures/HMM2.png\">\n",
    "\n",
    "**Figure 2:** Hidden Markov Model with three hidden states: (R)ainy, (S)unny and (W)indy. There are four types of observations: walking in the park (WP), shopping (SH), cleaning flat (CF) and visiting girlfriend (VG).\n",
    "\n",
    "Let's get back to our model in Example 1. Let's assume that we want to model one's behavior according to the weather outside. Let's name our hypothetical person Bob. Bob enjoys four activities: walking in park, shopping, cleaning flat and visiting girlfriend.\n",
    "\n",
    "We can code it in observation probability matrix B defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \n",
    "        \\begin{pmatrix}\n",
    "         & \\text{walk in park}   & \\text{shopping} & \\text{clean flat} & \\text{visit girlfriend} \\\\\n",
    "        rainy & 0.05 & 0.05 & 0.25 & 0.65 \\\\\n",
    "        sunny & 0.7 & 0.15 & 0.05 & 0.1 \\\\\n",
    "        windy & 0.25   & 0.4   & 0.05 & 0.3   \\\\\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09891732-f67b-4050-9db5-7da28bff769a",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "<img src=\"Figures/POS_tagging.jpeg\">\n",
    "\n",
    "**Figure 3:** Ambiguous POS tagging.\n",
    "\n",
    "We will focus on a problem of Part of Speech Tagging. As you know, sentences can be tricky to understand without context. This makes tagging part of speech (for instance nouns, adjectives) challenging task. In the file ``hw5-data-corpus/catalan_corpus_train_tagged.txt`` there are lines containing sentences in Catalan language with their tags. Use the loader code to read the data, then fill the missing code gaps to create a simple HMM model assuming that words are observations and tags are hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48c7412-1565-44c8-a17a-89583d782094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import sys\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53404038-fafc-40e3-aa0e-892fd724cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =\"hw5-data-corpus/catalan_corpus_train_tagged.txt\"\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.readlines()\n",
    "tag_sequences= []\n",
    "word_sequences = []\n",
    "tag_to_id = {}\n",
    "word_to_id = {}\n",
    "id_to_word = []\n",
    "id_to_tag =[]\n",
    "num_states = 10 # replace with the actual number of hidden states\n",
    "num_symbols = 1000 # replace with the actual number of observation symbols\n",
    "for line in data:\n",
    "    words = line.strip().split()\n",
    "    tag_sequences.append([])\n",
    "    word_sequences.append([])\n",
    "    for word in words:\n",
    "        try:\n",
    "            word, tag = word[:-3], word[-2:]\n",
    "        except:\n",
    "            print(word)\n",
    "        if word not in word_to_id.keys():\n",
    "            word_to_id[word] = len(id_to_word)\n",
    "            id_to_word.append(word)\n",
    "        if tag not in tag_to_id.keys():\n",
    "            tag_to_id[tag] = len(id_to_tag)\n",
    "            id_to_tag.append(tag)\n",
    "        word_sequences[-1].append(word_to_id[word])\n",
    "        tag_sequences[-1].append(tag_to_id[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86c191e-53ed-4231-bcf1-33f05085f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"*UNK*\"\n",
    "if word not in word_to_id.keys():\n",
    "    word_to_id[word] = len(id_to_word)\n",
    "    id_to_word.append(word)\n",
    "for tag in id_to_tag:\n",
    "    word_sequences[-1].append(word_to_id[word])\n",
    "    tag_sequences[-1].append(tag_to_id[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752f8a14-7681-473c-94c2-2ff831ed0837",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (921488963.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    init_probs =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "init_probs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961dd5dd-15a8-406a-8076-33828c467c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_prob = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44475dd-a7f7-4921-b81c-4e46e5033d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50f9f0-3b67-457b-8984-93f7378f6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(transition_prob.sum(axis=0), np.ones(len(tag_to_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ca361-9415-426d-9a79-4be4fe00e6d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Knowing joint distribution of the sequence of observations $O$ and states $Q$ conditioned on $\\lambda$ we can easily compute the probability we are looking for using the law of total probability.\n",
    "$$\n",
    "P(O | Q, \\lambda)=\\prod_{t=1}^{T} b_{q_{t}}\\left(o_{t}\\right).\n",
    "$$\n",
    "It is the direct result of Markov property.\n",
    "\n",
    "\n",
    "\n",
    "The probability of observing $O$ under condition $\\lambda$ is given by the equation:\n",
    "$$\n",
    "P(O | \\lambda)=\\sum_{q_{1} \\ldots q_{T} \\in \\mathbb{Q}_{\\mathbb{T}}} \\mu_{q_{1}} b_{q_{1}}\\left(o_{1}\\right) a_{q_{1} q_{2}} b_{q_{2}}\\left(o_{2}\\right) \\ldots a_{q_{T-1} q_{T}} b_{q_{T}}\\left(o_{T}\\right).\n",
    "$$\n",
    "\n",
    "Using this result would potentially allow us to evaluate the probability of $O$, but evaluating it directly has exponential complexity.\n",
    "\n",
    "A much better approach is to acknowledge that many redundant calculations is made by caching calculations can lead to reduced complexity. We implement the cache as a grid of states at each time step, calculating the cached valued (called $\\alpha$ ) for each state as a sum over all states at the previous time step. By $\\alpha$ we understand the probability of the partial observation sequence $o_{1}, o_{2} \\cdots o_{t}$ and state $s_{i}$ at time $t .$ Therefore, we define the forward probability variable:\n",
    "$$\n",
    "\\alpha_{t}(i)=P\\left(o_{1} o_{2} \\cdots o_{t}, q_{t}=s_{i} | \\lambda\\right).\n",
    "$$\n",
    "If we work through the grid filling in the values of $\\alpha$ the sum of the final column of the\n",
    "grid will equal the probability of the observation sequence.\n",
    "\n",
    "### Forward algorithm\n",
    "1. Initialisation:\n",
    "$$\n",
    "\\alpha_{1}(i)=\\pi_{i} b_{i}\\left(o_{1}\\right), 1 \\leq i \\leq N,\n",
    "$$\n",
    "2. Induction:\n",
    "$$\n",
    "\\alpha_{t+1}(j)=\\left[\\sum_{i=1}^{N} \\alpha_{t}(i) a_{i j}\\right] b_{j}\\left(o_{t+1}\\right), 1 \\leq t \\leq T-1,1 \\leq j \\leq N,\n",
    "$$\n",
    "3. Termination:\n",
    "$$\n",
    "P(O | \\lambda)=\\sum_{i=1}^{N} \\alpha_{T}(i),\n",
    "$$\n",
    "\n",
    "\n",
    "The induction step is the core of the forward algorithm. For each state $s_{j}, \\alpha_{j}(t)$ stores the probability of arriving in that state after observing the observation sequence up until time $t$.\n",
    "\n",
    "It is easy to notice that by caching $\\alpha$ values, the forward algorithm reduces the complexity of calculations involved to roughly $N^{2} T$ rather than $2 T N^{T}$. We can also define an analogous backward algorithm which is the exact reverse of the forward algorithm with the backward variable:\n",
    "$$\n",
    "\\beta_{t}(i)=P\\left(o_{t+1} o_{t+2} \\cdots o_{T} | q_{t}=s_{i}, \\lambda\\right),\n",
    "$$\n",
    "as the probability of the partial observation sequence from $t+1$ to $T,$ starting in state $s_{i}$.\n",
    "\n",
    "We can easily extend algorithm to work for continuous observation space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e61e2-b95a-4e80-91dc-a9d9995240e9",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Use the provided started code to compute probabilities of the 10 first sentences in file ``hw5-data-corpus/catalan_corpus_dev_tagged.txt``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c2b70-f62d-45d4-ba41-ab462181cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =\"hw5-data-corpus/catalan_corpus_dev_tagged.txt\"\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.readlines()\n",
    "testing_tag_sequences= []\n",
    "testing_word_sequences = []\n",
    "for line in data:\n",
    "    words = line.strip().split()\n",
    "    testing_tag_sequences.append([])\n",
    "    testing_word_sequences.append([])\n",
    "    for word in words:\n",
    "        try:\n",
    "            word, tag = word[:-3], word[-2:]\n",
    "            if word not in word_to_id.keys():\n",
    "                word = \"*UNK*\"\n",
    "        except:\n",
    "            print(word)\n",
    "        testing_word_sequences[-1].append(word_to_id[word])\n",
    "        testing_tag_sequences[-1].append(tag_to_id[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7a8df-16e6-4fd7-93ad-68a7c9297395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(a):\n",
    "    return np.log(np.sum(np.exp(a)))\n",
    "\n",
    "def forward(sequence, initial_probs, transition_matrix, emission_matrix):\n",
    "    pass\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135ee82-2b70-4ca4-9fff-a3345075bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_seq in testing_word_sequences[:10]:\n",
    "    print(forward(word_seq, init_probs, transition_prob, emission_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c85f20-0ec3-4361-ada5-1f14268a8644",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "The aim of decoding is to discover the hidden state sequence that was most likely to have\n",
    "produced a given observation sequence. One solution to this problem is to use the Viterbi\n",
    "algorithm to find the single best state sequence for an observation sequence.\n",
    " We want to compute \n",
    "$$\n",
    "    \\hat{\\mathbf{q}}=\\underset{\\mathbf{q}}{\\arg \\max } P(\\mathbf{q} | \\mathbf{o}).\n",
    "$$\n",
    "\n",
    "In general, solving this equation would demand a tedious search of all possible observation state sequences $\\mathbf{o}$, which would become impossible because of exponential complexity of this problem.\n",
    "Luckily, the structure of hidden Markov models brings us a reduction in the computational complexity.\n",
    "\n",
    "We know from Bayes' theorem that the posterior probability of observing a vector $\\mathbf{q}$ given that we have series of observations $\\mathbf{o}$ is expressed in terms of the observation likelihood $P(\\mathbf{q}|\\mathbf{o})$, the  prior distribution $P(\\mathbf{o})$ and the marginal distribution $P(\\mathbf{o})$ as\n",
    "$$\n",
    " P(\\mathbf{q} | \\mathbf{o})=\\frac{P(\\mathbf{o} | \\mathbf{q}) P(\\mathbf{q})}{P(\\mathbf{o})}.\n",
    "$$\n",
    "\n",
    "We can write observation likelihood using the independence property of observations:\n",
    "$$\\begin{array}{c}\n",
    "P(\\mathbf{o} | \\mathbf{q})=P\\left(o_{N}, o_{N-1}, \\cdots, o_{2}, o_{1}, o_{0} | q_{N}, q_{N-1}, \\cdots, q_{2}, q_{1}, q_{0}\\right)= \\\\\n",
    "P\\left(o_{N} | q_{N}\\right) \\cdots P\\left(o_{2} | q_{2}\\right) P\\left(o_{1} | q_{1}\\right) P\\left(o_{0} | q_{0}\\right)=\\prod_{n=0}^{N} P\\left(o_{n} | q_{n}\\right).\n",
    "\\end{array}$$\n",
    "The probability of observing the vector of states $\\mathbf{q}$ is given by considering the Markov property, using only the model transition probabilities:\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "P(\\mathbf{q})=P\\left(q_{N}, \\cdots, q_{2}, q_{1}, q_{0}\\right)= \\\\\n",
    "P\\left(q_{N} | q_{N-1}, \\cdots, q_{2}, q_{1}, q_{0}\\right) P\\left(q_{N-1} | q_{N-2}, \\cdots, q_{2}, q_{1}, q_{0}\\right) \\cdots P\\left(q_{1} | q_{0}\\right) P\\left(q_{0}\\right)= \\\\\n",
    "P\\left(q_{N} | q_{N-1}\\right) P\\left(q_{N-1} | q_{N-2}\\right) \\cdots P\\left(q_{1} | q_{0}\\right) P\\left(q_{0}\\right)=\\prod_{n=1}^{N} P\\left(q_{n} | q_{n-1}\\right) P\\left(q_{0}\\right).\n",
    "\\end{array}$$\n",
    "Using Bayes' rule we can write the a-posteriori probability as:\n",
    "$$P(\\mathbf{q} | \\mathbf{o})=\\frac{\\prod_{n=1}^{N} P\\left(o_{n} | q_{n}\\right) P\\left(q_{n} | q_{n-1}\\right) P\\left(q_{0}\\right)}{\\sum_{q_{N} \\in S} \\cdots \\sum_{q_{1} \\in S} \\sum_{q_{0} \\in S} \\prod_{m=1}^{N} P\\left(o_{n} | q_{n}\\right) P\\left(q_{n} | q_{n-1}\\right) P\\left(q_{0}\\right)},$$\n",
    "where $S$ is the set of all possible state values. The double product reduces to single product because each observation is conditionally dependent to a single Markov chain state.\n",
    "\n",
    "The nested sum denominator is computationally expensive. Luckily, we don't have to compute it because it ends up being a constant term. Actually, we can arrive at the same desired solution by maximizing the joint probability:\n",
    "$$\\underset{\\mathbf{q}}{\\arg \\max } P(\\mathbf{q} | \\mathbf{o})=\\underset{\\mathbf{q}}{\\arg \\max } P(\\mathbf{q}, \\mathbf{o}),$$\n",
    "which can be expanded using the observational conditional dependency and Markov properties to \n",
    "$$\\hat{\\mathbf{q}}=\\underset{\\mathbf{q}}{\\arg \\max } \\prod_{n=1}^{N} P\\left(o_{n} | q_{n}\\right) P\\left(q_{n} | q_{n-1}\\right) P\\left(q_{0}\\right).$$\n",
    "From a practical viewpoint it is often easier to maximize the log probability, because we avoid numerical errors:\n",
    "$$\\hat{\\mathbf{q}}=\\underset{\\mathbf{q}}{\\arg \\max } \\sum_{n=1}^{N}\\left(\\log P\\left(o_{n} | q_{n}\\right)+\\log P\\left(q_{n} | q_{n-1}\\right)\\right)+\\log P\\left(q_{0}\\right).$$\n",
    "\n",
    "We can now reduce the search to exploring a dataset for $\\mathbf{q}$ of size $N_{S}^{2}\\cdot $ using this algorithm, because now the exploration of all the permutations of $\\mathbf{q}$ and $\\mathbf{x}$ became redundant. At each time step,\n",
    "we check the paths that lead to each state from the possible old states. For each possible new state, we keep\n",
    "only the path coming from the previous state that has the largest probability, that is:\n",
    "$$V_{q}^{i}=\\max \\left(V_{q^{\\prime}}^{i-1}+\\log P\\left(q | q^{\\prime}\\right)+\\log P\\left(o | q^{i}\\right)\\right)$$\n",
    "for each time step. $V_{q}^{i}$ at each time step equals to the maximum cumulative log-probability achieved so\n",
    "far in transitioning from state $q^{\\prime}$ to $q.$ By recursively maximizing the joint probability for each possible new\n",
    "state, we maximize the final posterior probability of the entire sequence of states.\n",
    "\n",
    "<img src=\"Figures/viterbi1.png\">\n",
    "\n",
    "**Figure 4:** A single step  in the Viterbi algorithm.\n",
    "    By 1 we denote path segments that exhibit largest $V_n$ observing backward from Time 1 to Time 0. By 2 we denote the probability of observing $q_n$ equal to $i$ given transition with maximal likelihood. By 3 we denote prior probability. By 4 we denote likelihood of transition. By 5 we denote observation likelihood for observing output state i.\n",
    "\n",
    "<img src=\"Figures/viterbi2.png\">\n",
    "\n",
    "**Figure 5:** The development of the full paths from beginning to end.\n",
    "\n",
    "\n",
    "At any time step $k$ we use the running sum of log-probabilities as the prior probability\n",
    "$V_{1,2,3}^{k-1} .$ Next, we explore all possible transitions leading to the present state, leaving only the transition yielding the highest updated log-probabilities $V_{1,2,3}^{k}$. We keep a list of the most likely transitions and move on to the next step. After putting it all together, we build a series of paths.\n",
    "\n",
    "When we reach the end of the observation sequence, we choose the final sequence that has the highest log-probability and move backwards, following the transitions with highest\n",
    "probability until the start is reached. The path will trace out the most likely sequence of hidden states\n",
    "traversed by the Markov model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df553854-2071-41ee-a576-7d6edecf79cf",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Use the provided started code to decode all the sentences in file ``hw5-data-corpus/catalan_corpus_dev_tagged.txt``. Compute the accuracy score of the POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a002a-245c-4908-be37-6214e2d9e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sequence, initial_probs, transition_matrix, emission_matrix):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f751b4-bd27-48b7-8de4-1828d8eb5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(sequence, emission_matrix):\n",
    "    res = np.argmax(emission_matrix[:, sequence], axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebb8ff-3b63-4d81-8bf1-9a85490bca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, real = [], []\n",
    "for word_seq, tag_seq in zip(testing_word_sequences, testing_tag_sequences):\n",
    "    predicted.extend(viterbi(word_seq, init_probs, transition_prob, emission_prob))\n",
    "    real.extend(tag_seq)\n",
    "acc = (np.array(predicted) == np.array(real))\n",
    "print(np.sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3a2e1-9f14-4727-a09e-dd3b4e0872c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, real = [], []\n",
    "for word_seq, tag_seq in zip(testing_word_sequences, testing_tag_sequences):\n",
    "    predicted.extend(naive(word_seq, emission_prob))\n",
    "    real.extend(tag_seq)\n",
    "acc = (predicted == np.array(real))\n",
    "print(np.sum(acc)/len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
